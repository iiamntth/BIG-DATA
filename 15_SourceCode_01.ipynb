{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UGCfGh65ek0"
   },
   "source": [
    "# Xử lý data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-04T00:25:24.413780Z",
     "iopub.status.busy": "2025-06-04T00:25:24.413547Z",
     "iopub.status.idle": "2025-06-04T00:25:31.309139Z",
     "shell.execute_reply": "2025-06-04T00:25:31.308398Z",
     "shell.execute_reply.started": "2025-06-04T00:25:24.413756Z"
    },
    "id": "ARmbbzMk5ek4",
    "outputId": "f467db29-b243-43ce-8a0c-ffdf902734d0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/04 00:25:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi tạo Spark session\n",
    "spark = SparkSession.builder.appName(\"Sentiment140 + Reddit\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:25:31.310939Z",
     "iopub.status.busy": "2025-06-04T00:25:31.310339Z",
     "iopub.status.idle": "2025-06-04T00:25:37.581054Z",
     "shell.execute_reply": "2025-06-04T00:25:37.580254Z",
     "shell.execute_reply.started": "2025-06-04T00:25:31.310902Z"
    },
    "id": "bUpeFv2h5ek6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, lower\n",
    "\n",
    "# Đọc tập Sentiment140\n",
    "csv_path = \"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\"\n",
    "df_sent = spark.read.csv(csv_path, header=False, encoding=\"ISO-8859-1\")\n",
    "df_sent = df_sent.selectExpr(\"_c0 as raw_label\", \"_c5 as text\")\n",
    "df_sent = df_sent.filter(df_sent[\"raw_label\"].isin([\"0\", \"4\"]))\n",
    "df_sent = df_sent.withColumn(\"label\", (col(\"raw_label\") == \"4\").cast(\"integer\"))  # 0=neg, 1=pos\n",
    "\n",
    "# Làm sạch\n",
    "df_sent = df_sent.withColumn(\"clean_text\", lower(col(\"text\")))\n",
    "df_sent = df_sent.withColumn(\"clean_text\", regexp_replace(col(\"clean_text\"), r\"http\\S+\", \"\"))\n",
    "df_sent = df_sent.withColumn(\"clean_text\", regexp_replace(col(\"clean_text\"), r\"[^a-z\\s]\", \"\"))\n",
    "df_sent = df_sent.withColumn(\"clean_text\", regexp_replace(col(\"clean_text\"), r\"\\s+\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:25:37.582220Z",
     "iopub.status.busy": "2025-06-04T00:25:37.581931Z",
     "iopub.status.idle": "2025-06-04T00:25:38.015454Z",
     "shell.execute_reply": "2025-06-04T00:25:38.014688Z",
     "shell.execute_reply.started": "2025-06-04T00:25:37.582194Z"
    },
    "id": "Y35CrWu65ek6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Đọc Human Stress dataset\n",
    "human_path = \"/kaggle/input/human-stress-prediction/Stress.csv\"\n",
    "df_human = spark.read.csv(human_path, header=True)\n",
    "df_human = df_human.selectExpr(\"text as text\", \"`label` as raw_label\")\n",
    "df_human = df_human.filter(df_human[\"raw_label\"].isin([\"0\", \"1\"]))\n",
    "df_human = df_human.withColumn(\"label\", col(\"raw_label\").cast(\"integer\"))\n",
    "\n",
    "# Làm sạch\n",
    "df_human = df_human.withColumn(\"clean_text\", lower(col(\"text\")))\n",
    "df_human = df_human.withColumn(\"clean_text\", regexp_replace(col(\"clean_text\"), r\"http\\S+\", \"\"))\n",
    "df_human = df_human.withColumn(\"clean_text\", regexp_replace(col(\"clean_text\"), r\"[^a-z\\s]\", \"\"))\n",
    "df_human = df_human.withColumn(\"clean_text\", regexp_replace(col(\"clean_text\"), r\"\\s+\", \" \"))\n",
    "\n",
    "df_human = df_human.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:25:38.018098Z",
     "iopub.status.busy": "2025-06-04T00:25:38.017860Z",
     "iopub.status.idle": "2025-06-04T00:25:44.797082Z",
     "shell.execute_reply": "2025-06-04T00:25:44.796138Z",
     "shell.execute_reply.started": "2025-06-04T00:25:38.018057Z"
    },
    "id": "0RakoAPW5ek7",
    "outputId": "d95ba6d4-0651-40f4-febc-67e3c788a6e4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số dòng: 1602623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===============================================================>               (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    0|801250|\n",
      "|    1|801373|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "df_combined = df_sent.select(\"clean_text\", \"label\").unionByName(df_human.select(\"clean_text\", \"label\"))\n",
    "print(\"Tổng số dòng:\", df_combined.count())\n",
    "df_combined.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:25:44.798425Z",
     "iopub.status.busy": "2025-06-04T00:25:44.798163Z",
     "iopub.status.idle": "2025-06-04T00:26:13.970657Z",
     "shell.execute_reply": "2025-06-04T00:26:13.969477Z",
     "shell.execute_reply.started": "2025-06-04T00:25:44.798401Z"
    },
    "id": "Ks-Tit1m5ek7",
    "outputId": "2025f1bb-5bda-4a9a-f7df-7302699d6d09",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          clean_text|label|            features|\n",
      "+--------------------+-----+--------------------+\n",
      "|switchfoot awww t...|    0|(10000,[1528,2306...|\n",
      "|is upset that he ...|    0|(10000,[399,1939,...|\n",
      "|kenichan i dived ...|    0|(10000,[2708,3206...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Bỏ các dòng có clean_text bị null\n",
    "df_combined = df_combined.filter(df_combined[\"clean_text\"].isNotNull())\n",
    "\n",
    "# Pipeline xử lý văn bản\n",
    "tokenizer = Tokenizer(inputCol=\"clean_text\", outputCol=\"tokens\")\n",
    "stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_tokens\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stop_remover, hashing_tf, idf])\n",
    "pipeline_model = pipeline.fit(df_combined)\n",
    "df_tfidf = pipeline_model.transform(df_combined)\n",
    "\n",
    "# Xem thử\n",
    "df_tfidf.select(\"clean_text\", \"label\", \"features\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:26:13.972178Z",
     "iopub.status.busy": "2025-06-04T00:26:13.971541Z",
     "iopub.status.idle": "2025-06-04T00:27:43.849884Z",
     "shell.execute_reply": "2025-06-04T00:27:43.849272Z",
     "shell.execute_reply.started": "2025-06-04T00:26:13.972147Z"
    },
    "id": "og8gE3HY5ek7",
    "outputId": "95278d5d-88ea-42e5-f5f5-e0abaadffc7e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==============================================>                               (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng train: 1282141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng test: 320482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>switchfoot awww thats a bummer you shoulda got...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cant update his facebook by t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>strider is a sick little puppy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>so ryleegracewana go steves party or not sadly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hey i actually won one of my bracket pools too...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>stark you dont follow me either and i work for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>a bad nite for the favorite teams astros and s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_text  label\n",
       "0   switchfoot awww thats a bummer you shoulda got...      0\n",
       "1   is upset that he cant update his facebook by t...      0\n",
       "2   kenichan i dived many times for the ball manag...      0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4   nationwideclass no its not behaving at all im ...      0\n",
       "..                                                ...    ...\n",
       "95                    strider is a sick little puppy       0\n",
       "96  so ryleegracewana go steves party or not sadly...      0\n",
       "97  hey i actually won one of my bracket pools too...      0\n",
       "98  stark you dont follow me either and i work for...      0\n",
       "99  a bad nite for the favorite teams astros and s...      0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chia train/test theo tỉ lệ 80/20\n",
    "train_df, test_df = df_tfidf.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Số dòng train:\", train_df.count())\n",
    "print(\"Số dòng test:\", test_df.count())\n",
    "\n",
    "# Chuyển dữ liệu Spark → pandas để huấn luyện model torch\n",
    "sample_df = df_combined.select(\"clean_text\", \"label\").toPandas()\n",
    "sample_df = sample_df.dropna()\n",
    "sample_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH2UAGxv5ek8"
   },
   "source": [
    "# Mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:27:43.850974Z",
     "iopub.status.busy": "2025-06-04T00:27:43.850651Z",
     "iopub.status.idle": "2025-06-04T00:29:11.293040Z",
     "shell.execute_reply": "2025-06-04T00:29:11.292096Z",
     "shell.execute_reply.started": "2025-06-04T00:27:43.850957Z"
    },
    "id": "F1WE1DPl5ek8",
    "outputId": "46c79839-0f3a-4d95-987f-bc7917ad2be4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                                             (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------+-----+----------+-----------------------------------------+\n",
      "|clean_text                                                                                  |label|prediction|probability                              |\n",
      "+--------------------------------------------------------------------------------------------+-----+----------+-----------------------------------------+\n",
      "| a baby fell flat on his face and started bawling because of me forgot that he is wobbley   |0    |0.0       |[0.8921870665051995,0.10781293349480048] |\n",
      "| a car parked six inches away from my two door car i think i nearly broke my leg getting in |0    |0.0       |[0.9588027704677475,0.041197229532252466]|\n",
      "| a date night without my babysigh i miss you already                                        |0    |0.0       |[0.8825980759852103,0.11740192401478966] |\n",
      "| a free day from work and its rainy yay                                                     |0    |1.0       |[0.30440280193399366,0.6955971980660063] |\n",
      "| a lot of hacks is garena server but the games there are fun                                |0    |1.0       |[0.4095168379413727,0.5904831620586273]  |\n",
      "+--------------------------------------------------------------------------------------------+-----+----------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Khởi tạo mô hình Logistic Regression\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "lr_preds = lr_model.transform(test_df)\n",
    "\n",
    "# Hiển thị một vài dự đoán\n",
    "lr_preds.select(\"clean_text\", \"label\", \"prediction\", \"probability\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:29:11.293991Z",
     "iopub.status.busy": "2025-06-04T00:29:11.293738Z",
     "iopub.status.idle": "2025-06-04T00:29:45.372781Z",
     "shell.execute_reply": "2025-06-04T00:29:45.371930Z",
     "shell.execute_reply.started": "2025-06-04T00:29:11.293970Z"
    },
    "id": "c1lVTjEv5ek8",
    "outputId": "3b67713d-3b50-4bbc-c6f5-f9a1d4b15d43",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ROC AUC: 0.8269\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "lr_auc = evaluator.evaluate(lr_preds)\n",
    "\n",
    "print(f\"Logistic Regression ROC AUC: {lr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7Rs5tA5ek9"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:29:45.374085Z",
     "iopub.status.busy": "2025-06-04T00:29:45.373759Z",
     "iopub.status.idle": "2025-06-04T00:31:22.207058Z",
     "shell.execute_reply": "2025-06-04T00:31:22.206280Z",
     "shell.execute_reply.started": "2025-06-04T00:29:45.374025Z"
    },
    "id": "MmLQUpJL5ek9",
    "outputId": "e46929e5-d93a-47aa-dba5-0cbcae298f63",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (LinearSVC) ROC AUC: 0.8257\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# Khởi tạo và huấn luyện SVM\n",
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.1)\n",
    "svm_model = svm.fit(train_df)\n",
    "\n",
    "# Dự đoán\n",
    "svm_preds = svm_model.transform(test_df)\n",
    "svm_auc = evaluator.evaluate(svm_preds)\n",
    "\n",
    "print(f\"SVM (LinearSVC) ROC AUC: {svm_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:31:22.208520Z",
     "iopub.status.busy": "2025-06-04T00:31:22.207989Z",
     "iopub.status.idle": "2025-06-04T00:31:22.213355Z",
     "shell.execute_reply": "2025-06-04T00:31:22.212711Z",
     "shell.execute_reply.started": "2025-06-04T00:31:22.208490Z"
    },
    "id": "QqayBadr5ek9",
    "outputId": "82452da4-c0ea-4024-cda0-44a9a0dc7616",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả tổng hợp:\n",
      "Logistic Regression AUC: 0.8269\n",
      "SVM (LinearSVC)     AUC: 0.8257\n"
     ]
    }
   ],
   "source": [
    "print(\"Kết quả tổng hợp:\")\n",
    "print(f\"Logistic Regression AUC: {lr_auc:.4f}\")\n",
    "print(f\"SVM (LinearSVC)     AUC: {svm_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceI8A7iw5ek-"
   },
   "source": [
    "# biLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:31:22.214498Z",
     "iopub.status.busy": "2025-06-04T00:31:22.214235Z",
     "iopub.status.idle": "2025-06-04T00:31:34.099303Z",
     "shell.execute_reply": "2025-06-04T00:31:34.098434Z",
     "shell.execute_reply.started": "2025-06-04T00:31:22.214482Z"
    },
    "id": "LX0gxGy65ek-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "# Tạo vocab\n",
    "all_tokens = [token for text in sample_df[\"clean_text\"] for token in tokenize(text)]\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "vocab.update({word: i+2 for i, (word, _) in enumerate(Counter(all_tokens).most_common(10000))})\n",
    "\n",
    "def encode(text):\n",
    "    return [vocab.get(t, vocab[\"<UNK>\"]) for t in tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:31:34.100573Z",
     "iopub.status.busy": "2025-06-04T00:31:34.100260Z",
     "iopub.status.idle": "2025-06-04T00:32:03.575443Z",
     "shell.execute_reply": "2025-06-04T00:32:03.574838Z",
     "shell.execute_reply.started": "2025-06-04T00:31:34.100550Z"
    },
    "id": "vDGuf0kE5ek-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class BiLSTMDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.inputs = [torch.tensor(encode(t), dtype=torch.long) for t in texts]\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, labels = zip(*batch)\n",
    "    seqs = pad_sequence(seqs, batch_first=True, padding_value=0)\n",
    "    return seqs, torch.tensor(labels)\n",
    "\n",
    "# Chia tập train/test\n",
    "texts_train, texts_val, labels_train, labels_val = train_test_split(\n",
    "    sample_df[\"clean_text\"].tolist(), sample_df[\"label\"].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = BiLSTMDataset(texts_train, labels_train)\n",
    "val_ds = BiLSTMDataset(texts_val, labels_val)\n",
    "\n",
    "train_loader_bilstm = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader_bilstm = DataLoader(val_ds, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:32:03.578424Z",
     "iopub.status.busy": "2025-06-04T00:32:03.578097Z",
     "iopub.status.idle": "2025-06-04T00:32:03.584009Z",
     "shell.execute_reply": "2025-06-04T00:32:03.583471Z",
     "shell.execute_reply.started": "2025-06-04T00:32:03.578407Z"
    },
    "id": "k-5LI7Mz5ek-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = torch.cat((hn[0], hn[1]), dim=1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:32:56.944219Z",
     "iopub.status.busy": "2025-06-04T00:32:56.943529Z",
     "iopub.status.idle": "2025-06-04T00:37:07.891153Z",
     "shell.execute_reply": "2025-06-04T00:37:07.890360Z",
     "shell.execute_reply.started": "2025-06-04T00:32:56.944195Z"
    },
    "id": "p2ZBhpPR5ek_",
    "outputId": "d851e516-54c9-4816-8d31-2f7f133c8f7c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM Epoch 1 - Loss: 16736.2691\n",
      "BiLSTM Epoch 2 - Loss: 15046.9893\n",
      "BiLSTM Accuracy: 0.8252\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_bilstm = BiLSTMClassifier(len(vocab)).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_bilstm.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(2):\n",
    "    model_bilstm.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader_bilstm:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_bilstm(x_batch)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"BiLSTM Epoch {epoch+1} - Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Đánh giá\n",
    "model_bilstm.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader_bilstm:\n",
    "        x_batch = x_batch.to(device)\n",
    "        preds = torch.argmax(model_bilstm(x_batch), dim=1).cpu()\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "print(f\"BiLSTM Accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTc897gS5ek_"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:38:06.679159Z",
     "iopub.status.busy": "2025-06-04T00:38:06.678462Z",
     "iopub.status.idle": "2025-06-04T00:38:30.632706Z",
     "shell.execute_reply": "2025-06-04T00:38:30.631869Z",
     "shell.execute_reply.started": "2025-06-04T00:38:06.679133Z"
    },
    "id": "4G-GFBv15ek_",
    "outputId": "33ee6da4-7bc4-4800-c762-ac607960ff8d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 00:38:13.608997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748997493.870810      80 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748997493.942765      80 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_path = \"/kaggle/input/bert-base-uncased/bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:38:30.634794Z",
     "iopub.status.busy": "2025-06-04T00:38:30.634241Z",
     "iopub.status.idle": "2025-06-04T00:47:50.356886Z",
     "shell.execute_reply": "2025-06-04T00:47:50.356191Z",
     "shell.execute_reply.started": "2025-06-04T00:38:30.634776Z"
    },
    "id": "pEIK-5685ek_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize toàn bộ dữ liệu\n",
    "inputs = tokenizer(\n",
    "    list(sample_df[\"clean_text\"]),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "labels = torch.tensor(sample_df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:47:50.358196Z",
     "iopub.status.busy": "2025-06-04T00:47:50.357960Z",
     "iopub.status.idle": "2025-06-04T00:47:50.471883Z",
     "shell.execute_reply": "2025-06-04T00:47:50.471310Z",
     "shell.execute_reply.started": "2025-06-04T00:47:50.358177Z"
    },
    "id": "fCaWMjcQ5ek_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"], labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:49:49.688901Z",
     "iopub.status.busy": "2025-06-04T00:49:49.688604Z",
     "iopub.status.idle": "2025-06-04T09:28:44.514844Z",
     "shell.execute_reply": "2025-06-04T09:28:44.514132Z",
     "shell.execute_reply.started": "2025-06-04T00:49:49.688881Z"
    },
    "id": "SgeFLgGI5elA",
    "outputId": "79cfadcf-3c2f-42a6-8c49-7776ab4d83f1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40066/40066 [4:19:35<00:00,  2.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 14071.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40066/40066 [4:19:19<00:00,  2.58it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 11802.6419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(2):  # Huấn luyện 2 epoch\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids, attn_mask, labels = [x.to(device) for x in batch]\n",
    "        labels = labels.long()\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T09:28:55.757354Z",
     "iopub.status.busy": "2025-06-04T09:28:55.756781Z",
     "iopub.status.idle": "2025-06-04T09:46:28.457467Z",
     "shell.execute_reply": "2025-06-04T09:46:28.456810Z",
     "shell.execute_reply.started": "2025-06-04T09:28:55.757332Z"
    },
    "id": "mDiCpZ9A5elA",
    "outputId": "ff861aea-9370-4de9-ecce-aa05f124042f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá trên tập validation\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, attn_mask, labels = [x.to(model.device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T09:48:38.929811Z",
     "iopub.status.busy": "2025-06-04T09:48:38.929518Z",
     "iopub.status.idle": "2025-06-04T09:48:39.486986Z",
     "shell.execute_reply": "2025-06-04T09:48:39.486284Z",
     "shell.execute_reply.started": "2025-06-04T09:48:38.929792Z"
    },
    "id": "R_yhNZIf5elA",
    "outputId": "9855b59f-79bb-4704-eb6d-ca5fa97e8ee9",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/bert-sentiment-finetuned/tokenizer_config.json',\n",
       " '/kaggle/working/bert-sentiment-finetuned/special_tokens_map.json',\n",
       " '/kaggle/working/bert-sentiment-finetuned/vocab.txt',\n",
       " '/kaggle/working/bert-sentiment-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lưu mô hình fine-tuned\n",
    "model.save_pretrained(\"/kaggle/working/bert-sentiment-finetuned\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/bert-sentiment-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T11:05:37.314955Z",
     "iopub.status.busy": "2025-06-04T11:05:37.314658Z",
     "iopub.status.idle": "2025-06-04T11:05:37.633029Z",
     "shell.execute_reply": "2025-06-04T11:05:37.632376Z",
     "shell.execute_reply.started": "2025-06-04T11:05:37.314934Z"
    },
    "id": "wSMk9Ia85elA",
    "outputId": "6d842f0f-7627-4977-a254-08d42521797b",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_path = \"/kaggle/working/bert-sentiment-finetuned\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T11:05:42.138009Z",
     "iopub.status.busy": "2025-06-04T11:05:42.137739Z",
     "iopub.status.idle": "2025-06-04T11:05:42.568939Z",
     "shell.execute_reply": "2025-06-04T11:05:42.568329Z",
     "shell.execute_reply.started": "2025-06-04T11:05:42.137991Z"
    },
    "id": "DksgzjRe5elA",
    "outputId": "9bc7bd40-b84b-4a33-963e-0e6ce96046b1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn’t get out of bed until almost 2 PM\n",
      "   → Dự đoán: Negative (Confidence: 0.96)\n",
      "Not because I was tired, but because I couldn’t find a reason to move\n",
      "   → Dự đoán: Negative (Confidence: 0.97)\n",
      "I just laid there, staring at the wall, my chest so heavy it felt like breathing was a task\n",
      "   → Dự đoán: Negative (Confidence: 0.97)\n",
      "I didn’t eat anything\n",
      "   → Dự đoán: Negative (Confidence: 0.92)\n",
      "I didn’t talk to anyone\n",
      "   → Dự đoán: Negative (Confidence: 0.98)\n",
      "My phone buzzed a few times, but I couldn’t bring myself to care\n",
      "   → Dự đoán: Negative (Confidence: 0.91)\n",
      "Everything feels so distant—like I’m watching life through glass\n",
      "   → Dự đoán: Negative (Confidence: 0.95)\n",
      "I feel useless\n",
      "   → Dự đoán: Negative (Confidence: 0.99)\n",
      "Like I’m a burden to everyone around me\n",
      "   → Dự đoán: Negative (Confidence: 0.94)\n",
      "Sometimes I wonder if they’d be better off if I just disappeared\n",
      "   → Dự đoán: Negative (Confidence: 0.82)\n",
      "No one really sees me\n",
      "   → Dự đoán: Negative (Confidence: 0.95)\n",
      "They see the smile I force, the “I’m fine” I repeat, but not the emptiness that’s swallowing me inside\n",
      "   → Dự đoán: Negative (Confidence: 0.84)\n",
      "I don’t even remember what happiness feels like\n",
      "   → Dự đoán: Negative (Confidence: 0.66)\n",
      "I’m not living\n",
      "   → Dự đoán: Negative (Confidence: 0.85)\n",
      "I’m just… existing\n",
      "   → Dự đoán: Negative (Confidence: 0.53)\n",
      "\n",
      "Phân tích 15 câu:\n",
      "- Negative: 15\n",
      "- Positive: 0\n",
      "→ Tỉ lệ tiêu cực: 100.00%\n",
      "⚠️ Nguy cơ trầm cảm cao\n"
     ]
    }
   ],
   "source": [
    "# Ứng dụng\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "# Load lại mô hình đã fine-tuned\n",
    "model_path = \"/kaggle/working/bert-sentiment-finetuned\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Hàm chia văn bản thành câu\n",
    "def split_sentences(text):\n",
    "    text = re.sub(r\"\\n+\", \" \", text.strip())\n",
    "    return [s.strip() for s in re.split(r'[.!?]', text) if len(s.strip()) > 3]\n",
    "\n",
    "# Phân tích cảm xúc từng câu trong văn bản\n",
    "def analyze_document(text):\n",
    "    sentences = split_sentences(text)\n",
    "    if not sentences:\n",
    "        return \"Không có câu hợp lệ để phân tích.\"\n",
    "\n",
    "    negative_count = 0\n",
    "\n",
    "    for sent in sentences:\n",
    "        inputs = tokenizer(sent, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "        # In kết quả dự đoán từng câu\n",
    "        print(f\"{sent}\")\n",
    "        print(f\"   → Dự đoán: {'Negative' if pred == 0 else 'Positive'} (Confidence: {probs[0][pred]:.2f})\")\n",
    "\n",
    "        if pred == 0:\n",
    "            negative_count += 1\n",
    "\n",
    "    total = len(sentences)\n",
    "    ratio = negative_count / total\n",
    "    result = f\"\\nPhân tích {total} câu:\\n\" \\\n",
    "             f\"- Negative: {negative_count}\\n\" \\\n",
    "             f\"- Positive: {total - negative_count}\\n\" \\\n",
    "             f\"→ Tỉ lệ tiêu cực: {ratio:.2%}\\n\"\n",
    "\n",
    "    if ratio >= 0.7:\n",
    "        result += \"⚠️ Nguy cơ trầm cảm cao\"\n",
    "    elif ratio >= 0.5:\n",
    "        result += \"Biểu hiện tiêu cực thường xuyên\"\n",
    "    else:\n",
    "        result += \"Cảm xúc ổn định\"\n",
    "\n",
    "    return result\n",
    "\n",
    "# Thử với văn bản đầu vào\n",
    "test_text = \"\"\"\n",
    "I didn’t get out of bed until almost 2 PM. Not because I was tired, but because I couldn’t find a reason to move. I just laid there, staring at the wall, my chest so heavy it felt like breathing was a task. I didn’t eat anything. I didn’t talk to anyone. My phone buzzed a few times, but I couldn’t bring myself to care. Everything feels so distant—like I’m watching life through glass. I feel useless. Like I’m a burden to everyone around me. Sometimes I wonder if they’d be better off if I just disappeared. No one really sees me. They see the smile I force, the “I’m fine” I repeat, but not the emptiness that’s swallowing me inside. I don’t even remember what happiness feels like. I’m not living. I’m just… existing.\n",
    "\"\"\"\n",
    "print(analyze_document(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDrwD0p15elA"
   },
   "source": [
    "# Train ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:04:16.833503Z",
     "iopub.status.busy": "2025-06-04T17:04:16.833213Z",
     "iopub.status.idle": "2025-06-04T17:04:43.056157Z",
     "shell.execute_reply": "2025-06-04T17:04:43.055588Z",
     "shell.execute_reply.started": "2025-06-04T17:04:16.833478Z"
    },
    "id": "KucgOWeb5elA",
    "outputId": "ff136643-d4df-47dd-b4bc-29c974659bdc",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 17:04:29.114788: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749056669.294959      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749056669.344624      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Thư viện\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:04:43.057382Z",
     "iopub.status.busy": "2025-06-04T17:04:43.056843Z",
     "iopub.status.idle": "2025-06-04T17:04:43.114366Z",
     "shell.execute_reply": "2025-06-04T17:04:43.113832Z",
     "shell.execute_reply.started": "2025-06-04T17:04:43.057359Z"
    },
    "id": "8bs9gzsu5elB",
    "outputId": "755823c0-605f-45bd-f2e8-a9a8698d95a3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>gt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-00.jpg</td>\n",
       "      <td>Become a success with a disc and hey presto ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-01.jpg</td>\n",
       "      <td>assuredness \" Bella Bella Marie \" ( Parlophone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-02.jpg</td>\n",
       "      <td>I don't think he will storm the charts with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-03.jpg</td>\n",
       "      <td>CHRIS CHARLES , 39 , who lives in Stockton-on-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-116-00.jpg</td>\n",
       "      <td>He is also a director of a couple of garages ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image_path  \\\n",
       "0  /kaggle/input/iam-trocr/IAM/image/c04-110-00.jpg   \n",
       "1  /kaggle/input/iam-trocr/IAM/image/c04-110-01.jpg   \n",
       "2  /kaggle/input/iam-trocr/IAM/image/c04-110-02.jpg   \n",
       "3  /kaggle/input/iam-trocr/IAM/image/c04-110-03.jpg   \n",
       "4  /kaggle/input/iam-trocr/IAM/image/c04-116-00.jpg   \n",
       "\n",
       "                                             gt_text  \n",
       "0  Become a success with a disc and hey presto ! ...  \n",
       "1  assuredness \" Bella Bella Marie \" ( Parlophone...  \n",
       "2  I don't think he will storm the charts with th...  \n",
       "3  CHRIS CHARLES , 39 , who lives in Stockton-on-...  \n",
       "4  He is also a director of a couple of garages ....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load IAM thông qua gt_test.txt\n",
    "iam_root = Path(\"/kaggle/input/iam-trocr/IAM\")\n",
    "image_dir = iam_root / \"image\"\n",
    "gt_path = iam_root / \"gt_test.txt\"\n",
    "\n",
    "lines = gt_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.strip().split(maxsplit=1)\n",
    "    if len(parts) == 2:\n",
    "        img_name, text = parts\n",
    "        img_path = image_dir / img_name\n",
    "        data.append((str(img_path), text))\n",
    "# Tạo DataFrame IAM\n",
    "df_iam = pd.DataFrame(data, columns=[\"image_path\", \"gt_text\"])\n",
    "\n",
    "# Lấy ảnh để xử lý\n",
    "df_iam_small = df_iam.copy()\n",
    "df_iam_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:09:05.052224Z",
     "iopub.status.busy": "2025-06-04T17:09:05.051478Z",
     "iopub.status.idle": "2025-06-04T17:09:21.349862Z",
     "shell.execute_reply": "2025-06-04T17:09:21.349269Z",
     "shell.execute_reply.started": "2025-06-04T17:09:05.052197Z"
    },
    "id": "3dyqcVgh5elB",
    "outputId": "99868400-c85b-4c6f-b598-4d9af2c02e08",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 768,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at /kaggle/input/trocr-base-handwritten/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load mô hình TrOCR\n",
    "trocr_path = \"/kaggle/input/trocr-base-handwritten/trocr-base-handwritten\"\n",
    "\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(trocr_path)\n",
    "ocr_model = VisionEncoderDecoderModel.from_pretrained(trocr_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:09:21.356394Z",
     "iopub.status.busy": "2025-06-04T17:09:21.356167Z",
     "iopub.status.idle": "2025-06-04T17:09:21.389885Z",
     "shell.execute_reply": "2025-06-04T17:09:21.389272Z",
     "shell.execute_reply.started": "2025-06-04T17:09:21.356378Z"
    },
    "id": "7s-lKaR35elB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm OCR tối ưu\n",
    "def ocr_image(img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\").resize((512, 128))\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(ocr_model.device)\n",
    "    ids = ocr_model.generate(**inputs)\n",
    "    return processor.batch_decode(ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:09:21.391244Z",
     "iopub.status.busy": "2025-06-04T17:09:21.391068Z",
     "iopub.status.idle": "2025-06-04T17:18:59.192809Z",
     "shell.execute_reply": "2025-06-04T17:18:59.192065Z",
     "shell.execute_reply.started": "2025-06-04T17:09:21.391229Z"
    },
    "id": "hRp_FMVl5elB",
    "outputId": "454dbf89-c5f2-4edd-a142-a430def36b5d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy OCR ảnh IAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2915/2915 [09:37<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# OCR toàn bộ ảnh\n",
    "print(\"Đang chạy OCR ảnh IAM...\")\n",
    "df_iam_small[\"ocr_text\"] = [ocr_image(p) for p in tqdm(df_iam_small[\"image_path\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:19:02.983788Z",
     "iopub.status.busy": "2025-06-04T17:19:02.983519Z",
     "iopub.status.idle": "2025-06-04T17:19:02.988328Z",
     "shell.execute_reply": "2025-06-04T17:19:02.987484Z",
     "shell.execute_reply.started": "2025-06-04T17:19:02.983770Z"
    },
    "id": "RSMlrXEc5elB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def char_accuracy(pred, truth):\n",
    "    return SequenceMatcher(None, pred, truth).ratio()\n",
    "\n",
    "def word_accuracy(pred, truth):\n",
    "    pred_words = pred.strip().split()\n",
    "    truth_words = truth.strip().split()\n",
    "    return SequenceMatcher(None, pred_words, truth_words).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T17:19:18.465201Z",
     "iopub.status.busy": "2025-06-04T17:19:18.464955Z",
     "iopub.status.idle": "2025-06-04T17:19:18.712838Z",
     "shell.execute_reply": "2025-06-04T17:19:18.712059Z",
     "shell.execute_reply.started": "2025-06-04T17:19:18.465185Z"
    },
    "id": "UWeWOjby5elB",
    "outputId": "9f97f25c-82d2-4fad-cb21-d2e4996ba11f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trung bình (char-level): 0.9707\n",
      "Độ chính xác trung bình (word-level): 0.9170\n"
     ]
    }
   ],
   "source": [
    "# Tính từng hàng\n",
    "df_iam_small[\"char_acc\"] = df_iam_small.apply(lambda row: char_accuracy(row[\"ocr_text\"], row[\"gt_text\"]), axis=1)\n",
    "df_iam_small[\"word_acc\"] = df_iam_small.apply(lambda row: word_accuracy(row[\"ocr_text\"], row[\"gt_text\"]), axis=1)\n",
    "\n",
    "# Trung bình độ chính xác\n",
    "avg_char_acc = df_iam_small[\"char_acc\"].mean()\n",
    "avg_word_acc = df_iam_small[\"word_acc\"].mean()\n",
    "\n",
    "print(f\"Độ chính xác trung bình (char-level): {avg_char_acc:.4f}\")\n",
    "print(f\"Độ chính xác trung bình (word-level): {avg_word_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T11:15:32.699496Z",
     "iopub.status.busy": "2025-06-04T11:15:32.699248Z",
     "iopub.status.idle": "2025-06-04T11:15:55.262144Z",
     "shell.execute_reply": "2025-06-04T11:15:55.261524Z",
     "shell.execute_reply.started": "2025-06-04T11:15:32.699480Z"
    },
    "id": "ykanh6yp5elB",
    "outputId": "13443a72-6441-4075-c588-4ed2a41cd30b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang phân tích cảm xúc từ văn bản OCR...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>ocr_text</th>\n",
       "      <th>bert_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-00.jpg</td>\n",
       "      <td>Become a success with a disc and her presto ! ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-01.jpg</td>\n",
       "      <td>assuredness \" Bella Bella Marie \" ( Parlophone...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-02.jpg</td>\n",
       "      <td>I don't think he will storm the charts with th...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-110-03.jpg</td>\n",
       "      <td>CHRIS CHARLES , 39 , who lives in Stockton - o...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/c04-116-00.jpg</td>\n",
       "      <td>He is also a director of a couple of garages ....</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/d01-080-07.jpg</td>\n",
       "      <td>impossible to say .</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/d01-085-00.jpg</td>\n",
       "      <td>Professor E. A. Turner is inclined to take vie...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/d01-085-01.jpg</td>\n",
       "      <td>the original of the Gospel would be unmerced ....</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/d01-085-02.jpg</td>\n",
       "      <td>original of the Gospel , whether written on a ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>/kaggle/input/iam-trocr/IAM/image/d01-085-03.jpg</td>\n",
       "      <td>whether paragraphed or not , would be laid out in</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0   /kaggle/input/iam-trocr/IAM/image/c04-110-00.jpg   \n",
       "1   /kaggle/input/iam-trocr/IAM/image/c04-110-01.jpg   \n",
       "2   /kaggle/input/iam-trocr/IAM/image/c04-110-02.jpg   \n",
       "3   /kaggle/input/iam-trocr/IAM/image/c04-110-03.jpg   \n",
       "4   /kaggle/input/iam-trocr/IAM/image/c04-116-00.jpg   \n",
       "..                                               ...   \n",
       "95  /kaggle/input/iam-trocr/IAM/image/d01-080-07.jpg   \n",
       "96  /kaggle/input/iam-trocr/IAM/image/d01-085-00.jpg   \n",
       "97  /kaggle/input/iam-trocr/IAM/image/d01-085-01.jpg   \n",
       "98  /kaggle/input/iam-trocr/IAM/image/d01-085-02.jpg   \n",
       "99  /kaggle/input/iam-trocr/IAM/image/d01-085-03.jpg   \n",
       "\n",
       "                                             ocr_text bert_emotion  \n",
       "0   Become a success with a disc and her presto ! ...     Positive  \n",
       "1   assuredness \" Bella Bella Marie \" ( Parlophone...     Positive  \n",
       "2   I don't think he will storm the charts with th...     Positive  \n",
       "3   CHRIS CHARLES , 39 , who lives in Stockton - o...     Negative  \n",
       "4   He is also a director of a couple of garages ....     Positive  \n",
       "..                                                ...          ...  \n",
       "95                                impossible to say .     Negative  \n",
       "96  Professor E. A. Turner is inclined to take vie...     Positive  \n",
       "97  the original of the Gospel would be unmerced ....     Negative  \n",
       "98  original of the Gospel , whether written on a ...     Positive  \n",
       "99  whether paragraphed or not , would be laid out in     Positive  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=64).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        return \"Positive\" if pred == 1 else \"Negative\"\n",
    "\n",
    "# Dự đoán cảm xúc từ văn bản OCR\n",
    "print(\"Đang phân tích cảm xúc từ văn bản OCR...\")\n",
    "df_iam_small[\"bert_emotion\"] = df_iam_small[\"ocr_text\"].apply(predict_sentiment)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "df_iam_small[[\"image_path\", \"ocr_text\", \"bert_emotion\"]].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKx8CF5I5elB"
   },
   "source": [
    "# Thử nghiệm mô hình với bộ dữ liệu về E text khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T11:15:55.263037Z",
     "iopub.status.busy": "2025-06-04T11:15:55.262832Z",
     "iopub.status.idle": "2025-06-04T11:16:11.576363Z",
     "shell.execute_reply": "2025-06-04T11:16:11.575599Z",
     "shell.execute_reply.started": "2025-06-04T11:15:55.263021Z"
    },
    "id": "xwwH42mH5elB",
    "outputId": "8b232bb8-5e3b-4d26-a050-5f55a8e1508f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (dự đoán đúng các dòng 1): 0.7894\n",
      "→ Dự đoán đúng 2972/3765 dòng là có stress/anxiety\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Đọc dữ liệu Reddit Stress\n",
    "df_reddit = pd.read_csv(\"/kaggle/input/stress-and-anxiety-posts-on-reddit/stressed_anxious_cleaned.csv\")\n",
    "df_reddit = df_reddit[[\"Text\", \"is_stressed/anxious\"]].dropna()\n",
    "\n",
    "# Load mô hình đã fine-tuned\n",
    "model_path = \"/kaggle/working/bert-sentiment-finetuned\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Dự đoán theo batch\n",
    "def predict_batch(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=1)\n",
    "        return torch.argmax(probs, dim=1).cpu().numpy()\n",
    "\n",
    "batch_size = 32\n",
    "preds = []\n",
    "for i in tqdm(range(0, len(df_reddit), batch_size)):\n",
    "    batch_texts = df_reddit[\"Text\"].iloc[i:i+batch_size].tolist()\n",
    "    batch_preds = predict_batch(batch_texts)\n",
    "    preds.extend(batch_preds)\n",
    "\n",
    "# Gán nhãn gốc\n",
    "df_reddit[\"label\"] = 1  # Vì tất cả dòng là \"stressed/anxious\"\n",
    "\n",
    "# Dự đoán bằng mô hình đã load sẵn\n",
    "df_reddit[\"pred\"] = preds  # Từ mô hình\n",
    "\n",
    "# Tính số dòng dự đoán đúng (dự đoán được là 1)\n",
    "correct = (df_reddit[\"pred\"] == df_reddit[\"label\"]).sum()\n",
    "total = len(df_reddit)\n",
    "\n",
    "# Accuracy\n",
    "acc = correct / total\n",
    "print(f\"\\nAccuracy (dự đoán đúng các dòng 1): {acc:.4f}\")\n",
    "print(f\"→ Dự đoán đúng {correct}/{total} dòng là có stress/anxiety\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8ttgIe25elC"
   },
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T11:22:05.350387Z",
     "iopub.status.busy": "2025-06-04T11:22:05.350034Z",
     "iopub.status.idle": "2025-06-04T11:22:05.886420Z",
     "shell.execute_reply": "2025-06-04T11:22:05.885581Z",
     "shell.execute_reply.started": "2025-06-04T11:22:05.350360Z"
    },
    "id": "w2m8P4xI5elG",
    "outputId": "7322f03d-f786-4b82-c66d-f1119e62d3e3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/iiamntth/bert-sentiment-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='iiamntth/bert-sentiment-finetuned')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=\"iiamntth/bert-sentiment-finetuned\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "41cebc477bba4113ba378016e8ca56aa"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T11:22:23.769011Z",
     "iopub.status.busy": "2025-06-04T11:22:23.768363Z",
     "iopub.status.idle": "2025-06-04T11:22:33.769026Z",
     "shell.execute_reply": "2025-06-04T11:22:33.768377Z",
     "shell.execute_reply.started": "2025-06-04T11:22:23.768989Z"
    },
    "id": "951QUqS15elH",
    "outputId": "b3d9d775-c583-44d3-d15d-bc006bbd317c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cebc477bba4113ba378016e8ca56aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/iiamntth/bert-sentiment-finetuned/commit/0662131d926fc45378dd0f601d19e4da60c0ea93', commit_message='Upload folder using huggingface_hub', commit_description='', oid='0662131d926fc45378dd0f601d19e4da60c0ea93', pr_url=None, repo_url=RepoUrl('https://huggingface.co/iiamntth/bert-sentiment-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='iiamntth/bert-sentiment-finetuned'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_folder\n",
    "\n",
    "upload_folder(\n",
    "    folder_path=\"/kaggle/working/bert-sentiment-finetuned\",\n",
    "    repo_id=\"iiamntth/bert-sentiment-finetuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3Jlp2Wz5elH"
   },
   "source": [
    "# Tải"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T11:24:57.866268Z",
     "iopub.status.busy": "2025-06-04T11:24:57.865958Z",
     "iopub.status.idle": "2025-06-04T11:25:19.404914Z",
     "shell.execute_reply": "2025-06-04T11:25:19.404309Z",
     "shell.execute_reply.started": "2025-06-04T11:24:57.866248Z"
    },
    "id": "WthI28bs5elH",
    "outputId": "fe2847bd-bd02-4772-a2b4-5fd8a8cbbb8c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/bert-sentiment-finetuned.zip'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"/kaggle/working/bert-sentiment-finetuned\", 'zip', \"/kaggle/working/bert-sentiment-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ke3bnI75elH",
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2477,
     "sourceId": 4140,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2961947,
     "sourceId": 5100130,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4125061,
     "sourceId": 7145944,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5295427,
     "sourceId": 8805093,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7583397,
     "sourceId": 12049876,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7583491,
     "sourceId": 12050006,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7585921,
     "sourceId": 12053630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
